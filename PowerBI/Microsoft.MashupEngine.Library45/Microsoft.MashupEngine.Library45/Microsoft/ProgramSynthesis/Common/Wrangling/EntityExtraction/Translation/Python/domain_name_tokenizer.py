class DomainNameToken(EntityToken):
    class_id = EntityType.DomainName

    def __eq__(self, other):
        return self._value_based_equality(other)

    def __hash__(self):
        return self._value_based_hash()


class DomainNameTokenizer(RegexBasedTokenizer):
    """
    >>> t = DomainNameTokenizer()
    >>> tokens = list(t.match_tokens(r"www.google.com/specific_page.html"))
    >>> len(tokens)
    1
    >>> tokens[0].start
    4
    >>> tokens[0].end
    14
    >>> tokens = list(t.match_tokens("https://www.safaribooksonline.com/library/view/regular-expressions-cookbook/9781449327453/ch08s15.html"))
    >>> len(tokens)
    1
    >>> tokens[0].start
    12
    >>> tokens[0].end
    33
    >>> tokens = list(t.match_tokens(r"https://www.google.com/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=example%20urls"))
    >>> len(tokens)
    1
    >>> tokens[0].start
    12
    >>> tokens[0].end
    22
    """

    left_context_pattern_string = r'^|[^\-_\p{L}\p{N}]'
    right_context_pattern_string = r'$|[^\-_\p{L}\p{N}]'
    component_pattern_string = r'[\p{L}\p{N}][\p{L}\p{N}\-]*[\p{L}\p{N}]'
    domain_name_pattern_string = r'%s(?:\.%s)+' % (component_pattern_string, component_pattern_string)
    top_level_domain_names = frozenset([
        "ac",
        "ad",
        "ae",
        "af",
        "ag",
        "ai",
        "al",
        "am",
        "ao",
        "aq",
        "ar",
        "as",
        "at",
        "au",
        "aw",
        "ax",
        "az",
        "ba",
        "bb",
        "bd",
        "be",
        "bf",
        "bg",
        "bh",
        "bi",
        "bj",
        "bm",
        "bn",
        "bo",
        "br",
        "bs",
        "bt",
        "bv",
        "bw",
        "by",
        "bz",
        "ca",
        "cc",
        "cd",
        "cf",
        "cg",
        "ch",
        "ci",
        "ck",
        "cl",
        "cm",
        "cn",
        "co",
        "cr",
        "cu",
        "cv",
        "cw",
        "cx",
        "cy",
        "cz",
        "de",
        "dj",
        "dk",
        "dm",
        "do",
        "dz",
        "ec",
        "ee",
        "eg",
        "er",
        "es",
        "et",
        "eu",
        "fi",
        "fj",
        "fk",
        "fm",
        "fo",
        "fr",
        "ga",
        "gb",
        "gd",
        "ge",
        "gf",
        "gg",
        "gh",
        "gi",
        "gl",
        "gm",
        "gn",
        "gp",
        "gq",
        "gr",
        "gs",
        "gt",
        "gu",
        "gw",
        "gy",
        "hk",
        "hm",
        "hn",
        "hr",
        "ht",
        "hu",
        "id",
        "ie",
        "il",
        "im",
        "in",
        "io",
        "iq",
        "ir",
        "is",
        "it",
        "je",
        "jm",
        "jo",
        "jp",
        "ke",
        "kg",
        "kh",
        "ki",
        "km",
        "kn",
        "kp",
        "kr",
        "kw",
        "ky",
        "kz",
        "la",
        "lb",
        "lc",
        "li",
        "lk",
        "lr",
        "ls",
        "lt",
        "lu",
        "lv",
        "ly",
        "ma",
        "mc",
        "md",
        "me",
        "mg",
        "mh",
        "mk",
        "ml",
        "mm",
        "mn",
        "mo",
        "mp",
        "mq",
        "mr",
        "ms",
        "mt",
        "mu",
        "mv",
        "mw",
        "mx",
        "my",
        "mz",
        "na",
        "nc",
        "ne",
        "nf",
        "ng",
        "ni",
        "nl",
        "no",
        "np",
        "nr",
        "nu",
        "nz",
        "om",
        "pa",
        "pe",
        "pf",
        "pg",
        "ph",
        "pk",
        "pl",
        "pm",
        "pn",
        "pr",
        "ps",
        "pt",
        "pw",
        "py",
        "qa",
        "re",
        "ro",
        "rs",
        "ru",
        "rw",
        "sa",
        "sb",
        "sc",
        "sd",
        "se",
        "sg",
        "sh",
        "si",
        "sj",
        "sk",
        "sl",
        "sm",
        "sn",
        "so",
        "sr",
        "st",
        "su",
        "sv",
        "sx",
        "sy",
        "sz",
        "tc",
        "td",
        "tf",
        "tg",
        "th",
        "tj",
        "tk",
        "tl",
        "tm",
        "tn",
        "to",
        "tr",
        "tt",
        "tv",
        "tw",
        "tz",
        "ua",
        "ug",
        "uk",
        "us",
        "uy",
        "uz",
        "va",
        "vc",
        "ve",
        "vg",
        "vi",
        "vn",
        "vu",
        "wf",
        "ws",
        "ye",
        "yt",
        "za",
        "zm",
        "zw",
        "com",
        "org",
        "net",
        "int",
        "edu",
        "gov",
        "mil",
        "arpa",
        "info",
        "xyz",
        "biz"
    ]
    )

    def __init__(self):
        super().__init__(OverlapStrategy.SUBSUMPTION,
                         TokenPattern(DomainNameTokenizer.domain_name_pattern_string,
                                      DomainNameTokenizer.left_context_pattern_string,
                                      DomainNameTokenizer.right_context_pattern_string))

    def process_matches(self, matches):
        for m in matches:
            start = m.start
            value = m.get_value()
            if value.startswith('www.'):
                if len(value) <= 4:
                    return
                start = m.start + 4 if (value.startswith('www.')) else m.start
            tld = value.split('.')
            tld = tld[len(tld) - 1]
            if tld in DomainNameTokenizer.top_level_domain_names:
                yield DomainNameToken(m.source, start, m.end)
